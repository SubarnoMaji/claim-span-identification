{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8732695,"sourceType":"datasetVersion","datasetId":5241859}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dhWTKISOW3lf","outputId":"c3ae426b-1cc8-4c27-b0a9-d7977070c3d7","execution":{"iopub.status.busy":"2024-06-20T07:10:42.068544Z","iopub.execute_input":"2024-06-20T07:10:42.069256Z","iopub.status.idle":"2024-06-20T07:10:42.398259Z","shell.execute_reply.started":"2024-06-20T07:10:42.069221Z","shell.execute_reply":"2024-06-20T07:10:42.396975Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"],"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"id":"3AUVFRF8W9GO","execution":{"iopub.status.busy":"2024-06-22T14:17:09.788555Z","iopub.execute_input":"2024-06-22T14:17:09.789034Z","iopub.status.idle":"2024-06-22T14:17:09.793663Z","shell.execute_reply.started":"2024-06-22T14:17:09.788994Z","shell.execute_reply":"2024-06-22T14:17:09.792394Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_en = pd.read_json('/kaggle/input/icprdata/ICPR/train-en.json')\nval_en = pd.read_json('/kaggle/input/icprdata/ICPR/val-en.json')\n","metadata":{"id":"JWqqitG9XHkS","execution":{"iopub.status.busy":"2024-06-22T14:17:10.074670Z","iopub.execute_input":"2024-06-22T14:17:10.075439Z","iopub.status.idle":"2024-06-22T14:17:10.257590Z","shell.execute_reply.started":"2024-06-22T14:17:10.075405Z","shell.execute_reply":"2024-06-22T14:17:10.256689Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(val_en.iloc[9])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lIP-TqJ6cHgz","outputId":"d97346d8-a5d0-4f79-d464-c7e0f3b84a35","execution":{"iopub.status.busy":"2024-06-22T14:17:10.372010Z","iopub.execute_input":"2024-06-22T14:17:10.373083Z","iopub.status.idle":"2024-06-22T14:17:10.395313Z","shell.execute_reply.started":"2024-06-22T14:17:10.373025Z","shell.execute_reply":"2024-06-22T14:17:10.394179Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"index                                                          9\nclaims         [{'index': 0, 'start': 6, 'end': 14, 'terms': ...\ntext_tokens    [Wait, !, Did, I, just, hear, Hancock, backtra...\nName: 9, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"\nprint(train_en.iloc[9])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JLWcUr4aXK5Y","outputId":"56cc4cbf-cb67-46e3-ae57-aaf215b93fca","execution":{"iopub.status.busy":"2024-06-22T14:17:10.636526Z","iopub.execute_input":"2024-06-22T14:17:10.637445Z","iopub.status.idle":"2024-06-22T14:17:10.644011Z","shell.execute_reply.started":"2024-06-22T14:17:10.637407Z","shell.execute_reply":"2024-06-22T14:17:10.643080Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"index                                                        509\nclaims         [{'index': 0, 'start': 26, 'end': 33, 'terms':...\ntext_tokens    [COVID, 19, mortality, Stats, have, been, hamm...\nName: 9, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_en.iloc[9]['text_tokens'][26:33])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TscZfWtMXP_9","outputId":"213da707-7d8d-4dae-9439-42cf45930848","execution":{"iopub.status.busy":"2024-06-22T14:17:10.861995Z","iopub.execute_input":"2024-06-22T14:17:10.862353Z","iopub.status.idle":"2024-06-22T14:17:10.868217Z","shell.execute_reply.started":"2024-06-22T14:17:10.862324Z","shell.execute_reply":"2024-06-22T14:17:10.867100Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['imprisonment', 'to', 'prove', 'living', 'in', 'abject', 'fear']\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import XLMRobertaTokenizerFast\n\n# Load the tokenizer\ntokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\", add_prefix_space=True)\n\ndef assign_labels(example):\n    claims = example['claims']\n    tokens = example['text_tokens']\n    labels = np.zeros(len(tokens))\n    for claim in claims:\n        start = claim['start']\n        end = claim['end']\n        for i in range(start, end):\n            labels[i] = 1\n    return labels\n\ndef align_labels_with_tokens(labels, word_ids):\n    new_labels = []\n    for word_id in word_ids:\n        if word_id is None:\n            new_labels.append(-100)\n        else:\n            new_labels.append(labels[word_id])\n    return new_labels\n\ndef preprocess(train_set, tokenizer):\n    new_labels = []\n    encodings = tokenizer(train_set['text_tokens'].tolist(), is_split_into_words=True, padding=False)\n    for i, example in train_set.iterrows():\n        labels = assign_labels(example)\n        word_ids = encodings.word_ids(batch_index=i)\n        new_labels.append(align_labels_with_tokens(labels, word_ids))\n    return encodings, new_labels\n\nclass CustomDataset(Dataset):\n    def __init__(self, dataset, tokenizer):\n        self.encodings, self.labels = preprocess(dataset, tokenizer)\n        self.input_ids = self.encodings['input_ids']\n        self.attention_mask = self.encodings['attention_mask']\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        input_ids = torch.tensor(self.input_ids[idx], dtype=torch.int64)\n        attention_mask = torch.tensor(self.attention_mask[idx], dtype=torch.int64)\n        labels = torch.tensor(self.labels[idx], dtype=torch.int64)\n        return input_ids, attention_mask, labels\n\ndef collate_fn(batch):\n    input_ids = [item[0] for item in batch]\n    attention_mask = [item[1] for item in batch]\n    labels = [item[2] for item in batch]\n\n    max_length = max(len(ids) for ids in input_ids)\n\n    padded_input_ids = torch.stack([torch.nn.functional.pad(ids, (0, max_length - len(ids)), value=tokenizer.pad_token_id) for ids in input_ids])\n    padded_attention_mask = torch.stack([torch.nn.functional.pad(mask, (0, max_length - len(mask)), value=0) for mask in attention_mask])\n    padded_labels = torch.stack([torch.nn.functional.pad(label, (0, max_length - len(label)), value=-100) for label in labels])\n\n    return padded_input_ids, padded_attention_mask, padded_labels\n\n\n","metadata":{"id":"xDLdpa1uaw2J","execution":{"iopub.status.busy":"2024-06-22T14:17:11.107787Z","iopub.execute_input":"2024-06-22T14:17:11.108133Z","iopub.status.idle":"2024-06-22T14:17:19.288022Z","shell.execute_reply.started":"2024-06-22T14:17:11.108108Z","shell.execute_reply":"2024-06-22T14:17:19.287093Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb75bc1204a14a418548552048c2c08b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d671fa569a21462484f488c48e1704bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"623122e70011429095f7c53dff203ee1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d1b9716a35143458bf670685d503ac5"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = CustomDataset(train_en, tokenizer)\nval_dataset = CustomDataset(val_en, tokenizer)\n\nBATCH_SIZE = 16\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn) ","metadata":{"execution":{"iopub.status.busy":"2024-06-22T14:17:19.289932Z","iopub.execute_input":"2024-06-22T14:17:19.290656Z","iopub.status.idle":"2024-06-22T14:17:20.822461Z","shell.execute_reply.started":"2024-06-22T14:17:19.290603Z","shell.execute_reply":"2024-06-22T14:17:20.821660Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"next(iter(train_dataloader))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jtMxaKK_sHi7","outputId":"e9fc0dbc-a3ef-4e9a-e673-ebf25972b973","execution":{"iopub.status.busy":"2024-06-22T14:17:20.823950Z","iopub.execute_input":"2024-06-22T14:17:20.824302Z","iopub.status.idle":"2024-06-22T14:17:20.895589Z","shell.execute_reply.started":"2024-06-22T14:17:20.824270Z","shell.execute_reply":"2024-06-22T14:17:20.894739Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(tensor([[     0,    468,  16350,  ...,     31,   2525,      2],\n         [     0,   1401,     25,  ...,      1,      1,      1],\n         [     0,  88046,    450,  ...,      1,      1,      1],\n         ...,\n         [     0,   1374,   1062,  ...,      1,      1,      1],\n         [     0,  45764,     92,  ...,      1,      1,      1],\n         [     0, 103993,  43975,  ...,      1,      1,      1]]),\n tensor([[1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         ...,\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0]]),\n tensor([[-100,    0,    0,  ...,    0,    0, -100],\n         [-100,    1,    1,  ..., -100, -100, -100],\n         [-100,    0,    0,  ..., -100, -100, -100],\n         ...,\n         [-100,    0,    0,  ..., -100, -100, -100],\n         [-100,    1,    1,  ..., -100, -100, -100],\n         [-100,    0,    0,  ..., -100, -100, -100]]))"},"metadata":{}}]},{"cell_type":"code","source":"len(train_dataloader) , len(val_dataloader)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iSAJCTMD6qEm","outputId":"e96fcfeb-38c8-4c0f-e3ca-b12fd00e5263","execution":{"iopub.status.busy":"2024-06-22T14:17:20.898028Z","iopub.execute_input":"2024-06-22T14:17:20.898605Z","iopub.status.idle":"2024-06-22T14:17:20.904487Z","shell.execute_reply.started":"2024-06-22T14:17:20.898570Z","shell.execute_reply":"2024-06-22T14:17:20.903564Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(375, 32)"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import XLMRobertaModel, BertPreTrainedModel\n\nclass BaseModel1(BertPreTrainedModel):\n    def __init__(self, conf):\n        super(BaseModel1, self).__init__(conf)\n        self.roberta = XLMRobertaModel.from_pretrained('xlm-roberta-large', output_hidden_states=True, add_pooling_layer=False)\n        self.high_dropout = torch.nn.Dropout(0.3)\n        self.classifier = nn.Sequential(\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 2)\n        )\n        \n        for module in self.classifier:\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_uniform_(module.weight)\n\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, ids, attention_mask):\n        outputs = self.roberta(ids, attention_mask=attention_mask)\n        out = outputs.last_hidden_state\n        \n        out = torch.mean(torch.stack([\n            self.classifier(self.high_dropout(out))\n            for _ in range(8)\n        ], dim=0), dim=0)\n        \n\n        out = self.softmax(out)\n        \n        return out\n","metadata":{"execution":{"iopub.status.busy":"2024-06-22T14:17:20.905740Z","iopub.execute_input":"2024-06-22T14:17:20.906038Z","iopub.status.idle":"2024-06-22T14:17:22.281734Z","shell.execute_reply.started":"2024-06-22T14:17:20.906014Z","shell.execute_reply":"2024-06-22T14:17:22.280236Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nloss_function = nn.CrossEntropyLoss(ignore_index=-100)\n\ndef smooth_labels(labels, smoothing=0.25):\n    num_classes = labels.size(1)\n    smooth_labels = labels * (1 - smoothing) + (smoothing / num_classes)\n    mask = labels == -100\n    smooth_labels[mask] = labels[mask]\n    return smooth_labels\n\ndef cross_entropy_with_label_smoothing(y_true, y_pred, smoothing=0.25):\n    y_true_smoothed = smooth_labels(y_true, smoothing)\n    y_true_smoothed = y_true_smoothed.view(-1)\n    \n    log_probs = torch.log(y_pred)\n    log_probs = torch.clamp(log_probs , min = -1e10)\n\n    log_probs1 =log_probs[:,:,1].view(-1)\n    log_probs2 =log_probs[:,:,0].view(-1)\n\n    valid_mask = y_true != -100\n    valid_mask =  valid_mask.view(-1)\n\n    loss1 = -(y_true_smoothed[valid_mask] * log_probs1[valid_mask]).sum() / valid_mask.sum()\n    loss2 = -((1 - y_true_smoothed[valid_mask]) * log_probs2[valid_mask]).sum() / valid_mask.sum()\n \n    \n    return loss1 + loss2","metadata":{"execution":{"iopub.status.busy":"2024-06-22T14:17:22.283034Z","iopub.execute_input":"2024-06-22T14:17:22.283879Z","iopub.status.idle":"2024-06-22T14:17:22.292735Z","shell.execute_reply.started":"2024-06-22T14:17:22.283843Z","shell.execute_reply":"2024-06-22T14:17:22.291832Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nimport torch.nn as nn\n\ndef accuracy_score(preds, labels):\n    mask = labels != -100\n    preds = preds[mask]\n    labels = labels[mask]\n    return (preds == labels).sum().item() / len(labels)\n\ndef train_model(model, train_dataloader, val_dataloader, device, epochs=3):\n    model = model.to(device)\n    optimizer = AdamW(model.parameters(), lr=1e-5)\n    total_steps = len(train_dataloader) * epochs\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n    loss_function = nn.CrossEntropyLoss(ignore_index=-100)\n\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0.0\n        correct_predictions = 0.0  \n\n        print(f\"Epoch {epoch+1}/{epochs}\")\n\n        train_progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{epochs}, Training')\n\n        for batch in train_progress_bar:\n            ids = batch[0].to(device)\n            attention_mask = batch[1].to(device)\n            labels = batch[2].to(device)\n\n            outputs = model(ids, attention_mask)\n\n            loss =  cross_entropy_with_label_smoothing(labels.float(),outputs.float())\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n            train_loss += loss.item()\n\n            _, preds = torch.max(outputs, dim=2)\n            correct_predictions += accuracy_score(preds, labels) * ids.size(0)  # Update correct_predictions\n\n            train_progress_bar.set_postfix({'Training Loss': train_loss / (train_progress_bar.n + 1), 'Training Acc': correct_predictions / len(train_dataloader.dataset)})\n     \n        avg_train_loss = train_loss / len(train_dataloader)\n        train_accuracy = correct_predictions / len(train_dataloader.dataset)  # Calculate accuracy over entire dataset\n\n        print(f\"Training loss: {avg_train_loss}, Training accuracy: {train_accuracy}\")\n\n        model.eval()\n        val_loss = 0.0\n        correct_predictions = 0.0  \n\n        val_progress_bar = tqdm(val_dataloader, desc=f'Epoch {epoch+1}/{epochs}, Validation')\n\n        with torch.no_grad():\n            for batch in val_progress_bar:\n                ids = batch[0].to(device)\n                attention_mask = batch[1].to(device)\n                labels = batch[2].to(device)\n\n                outputs = model(ids, attention_mask)\n                loss =  cross_entropy_with_label_smoothing(labels.float(),outputs.float())\n\n                val_loss += loss.item()\n\n                _, preds = torch.max(outputs, dim=2)\n                correct_predictions += accuracy_score(preds, labels) * ids.size(0)  # Update correct_predictions\n\n                val_progress_bar.set_postfix({'Validation Loss': val_loss / (val_progress_bar.n + 1), 'Validation Acc': correct_predictions / len(val_dataloader.dataset)})\n\n        avg_val_loss = val_loss / len(val_dataloader)\n        val_accuracy = correct_predictions / len(val_dataloader.dataset)  # Calculate accuracy over entire dataset\n\n        print(f\"Validation loss: {avg_val_loss}, Validation accuracy: {val_accuracy}\")\n","metadata":{"id":"IqU8AFJ4n2k7","execution":{"iopub.status.busy":"2024-06-22T14:17:22.807323Z","iopub.execute_input":"2024-06-22T14:17:22.807711Z","iopub.status.idle":"2024-06-22T14:17:22.834670Z","shell.execute_reply.started":"2024-06-22T14:17:22.807682Z","shell.execute_reply":"2024-06-22T14:17:22.833714Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import XLMRobertaModel, BertPreTrainedModel, XLMRobertaConfig\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nconfiguration = XLMRobertaConfig()\n\nmodel = BaseModel1(configuration).to(device)\n","metadata":{"id":"AfjyuOsmoL-v","execution":{"iopub.status.busy":"2024-06-22T14:17:30.802152Z","iopub.execute_input":"2024-06-22T14:17:30.802752Z","iopub.status.idle":"2024-06-22T14:17:40.216218Z","shell.execute_reply.started":"2024-06-22T14:17:30.802720Z","shell.execute_reply":"2024-06-22T14:17:40.215139Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50ae3944c0694665895ca5ae09621153"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fd6a957c08e489da045e7445cf45f8d"}},"metadata":{}}]},{"cell_type":"code","source":"train_model(model, train_dataloader, val_dataloader, device, epochs=5)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"vbi0epvRsHi7","outputId":"2f4b5668-b90e-45eb-a933-0ce819e28b06","execution":{"iopub.status.busy":"2024-06-22T14:17:47.178120Z","iopub.execute_input":"2024-06-22T14:17:47.178502Z","iopub.status.idle":"2024-06-22T14:35:42.598465Z","shell.execute_reply.started":"2024-06-22T14:17:47.178473Z","shell.execute_reply":"2024-06-22T14:35:42.597535Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5, Training: 100%|██████████| 375/375 [03:30<00:00,  1.78it/s, Training Loss=0.427, Training Acc=0.773] \n","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.4270086154937744, Training accuracy: 0.7732111416937256\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5, Validation: 100%|██████████| 32/32 [00:05<00:00,  5.89it/s, Validation Loss=0.404, Validation Acc=0.799]\n","output_type":"stream"},{"name":"stdout","text":"Validation loss: 0.40431526210159063, Validation accuracy: 0.7993676802094607\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5, Training: 100%|██████████| 375/375 [03:29<00:00,  1.79it/s, Training Loss=0.381, Training Acc=0.824]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.3809818849563599, Training accuracy: 0.8238940780399886\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5, Validation: 100%|██████████| 32/32 [00:05<00:00,  5.88it/s, Validation Loss=0.412, Validation Acc=0.807]\n","output_type":"stream"},{"name":"stdout","text":"Validation loss: 0.4120252002030611, Validation accuracy: 0.807085424854929\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5, Training: 100%|██████████| 375/375 [03:29<00:00,  1.79it/s, Training Loss=0.358, Training Acc=0.851]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.35825894383589424, Training accuracy: 0.8506386861599843\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5, Validation: 100%|██████████| 32/32 [00:05<00:00,  5.92it/s, Validation Loss=0.423, Validation Acc=0.811]\n","output_type":"stream"},{"name":"stdout","text":"Validation loss: 0.422676682472229, Validation accuracy: 0.8112979356239557\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5, Training: 100%|██████████| 375/375 [03:29<00:00,  1.79it/s, Training Loss=0.336, Training Acc=0.874]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.33603576521078743, Training accuracy: 0.8739802586841703\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5, Validation: 100%|██████████| 32/32 [00:05<00:00,  5.91it/s, Validation Loss=0.434, Validation Acc=0.81] \n","output_type":"stream"},{"name":"stdout","text":"Validation loss: 0.4339686958119273, Validation accuracy: 0.8102193251091466\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5, Training: 100%|██████████| 375/375 [03:29<00:00,  1.79it/s, Training Loss=0.317, Training Acc=0.892]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.31723575095335643, Training accuracy: 0.8923869514917406\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5, Validation: 100%|██████████| 32/32 [00:05<00:00,  5.92it/s, Validation Loss=0.428, Validation Acc=0.811]","output_type":"stream"},{"name":"stdout","text":"Validation loss: 0.42769539076834917, Validation accuracy: 0.8114371350824616\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# PATH = \"model__0.pt\"\n\n# torch.save(model.state_dict(),PATH)","metadata":{"id":"i_mUsVc8sHi8","execution":{"iopub.status.busy":"2024-06-22T14:37:18.349120Z","iopub.execute_input":"2024-06-22T14:37:18.349537Z","iopub.status.idle":"2024-06-22T14:37:18.354133Z","shell.execute_reply.started":"2024-06-22T14:37:18.349508Z","shell.execute_reply":"2024-06-22T14:37:18.353065Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Taking Prediction for the Val Set","metadata":{"id":"nksnh9-MwigC"}},{"cell_type":"code","source":"BATCH_SIZE = 1\nval_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE , shuffle = False)","metadata":{"id":"Xkceq1q41JdM","execution":{"iopub.status.busy":"2024-06-22T14:37:18.894646Z","iopub.execute_input":"2024-06-22T14:37:18.895462Z","iopub.status.idle":"2024-06-22T14:37:18.900447Z","shell.execute_reply.started":"2024-06-22T14:37:18.895421Z","shell.execute_reply":"2024-06-22T14:37:18.899367Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"predictions = []\npred = None\nwith torch.no_grad():\n        for batch in tqdm(val_dataloader):\n                ids = batch[0].to(device)\n                attention_mask = batch[1].to(device)\n                labels = batch[2].to(device)\n\n                outputs = model(ids, attention_mask)\n                pred = F.softmax(outputs, dim=-1)\n                predictions.append(pred[:,:,1].tolist())\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oGSeMoyssHi8","outputId":"3cbadab8-4aca-4d44-ef4f-126c11bdb72b","execution":{"iopub.status.busy":"2024-06-22T14:37:19.699175Z","iopub.execute_input":"2024-06-22T14:37:19.699854Z","iopub.status.idle":"2024-06-22T14:37:29.616428Z","shell.execute_reply.started":"2024-06-22T14:37:19.699822Z","shell.execute_reply":"2024-06-22T14:37:29.615564Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"100%|██████████| 500/500 [00:09<00:00, 50.47it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"reshaped_predictions = []\nfor prediction in predictions:\n    for i in prediction:\n        reshaped_predictions.append(i)\npredictions = reshaped_predictions","metadata":{"execution":{"iopub.status.busy":"2024-06-22T14:37:48.801576Z","iopub.execute_input":"2024-06-22T14:37:48.801955Z","iopub.status.idle":"2024-06-22T14:37:48.807073Z","shell.execute_reply.started":"2024-06-22T14:37:48.801928Z","shell.execute_reply":"2024-06-22T14:37:48.806055Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.array(predictions)\n","metadata":{"id":"DMb7CDeS85I2","execution":{"iopub.status.busy":"2024-06-22T14:37:50.436434Z","iopub.execute_input":"2024-06-22T14:37:50.437064Z","iopub.status.idle":"2024-06-22T14:37:50.769545Z","shell.execute_reply.started":"2024-06-22T14:37:50.437034Z","shell.execute_reply":"2024-06-22T14:37:50.768309Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (500,) + inhomogeneous part."],"ename":"ValueError","evalue":"setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (500,) + inhomogeneous part.","output_type":"error"}]},{"cell_type":"markdown","source":"## Post Processing","metadata":{"id":"hU9-QzGs0HQa"}},{"cell_type":"code","source":"def preprocess(train_set):\n  encoding = tokenizer(train_set['text_tokens'].tolist(), is_split_into_words = True, padding = True, return_tensors ='pt',)\n  new_labels = []\n  word_ids_list = []\n  for i,example in train_set.iterrows():\n    labels = assign_labels(example)\n    word_ids = encoding[i].word_ids\n    new_labels.append(allign_labels_with_tokens(labels,word_ids))\n    word_ids_list.append( word_ids)\n  padded_labels = pad_labels(new_labels)\n  encoding['targets'] = padded_labels\n  encoding['word_ids'] = word_ids_list\n  return encoding\n","metadata":{"id":"6OAzhj0a36hE","execution":{"iopub.status.busy":"2024-06-22T14:37:53.464117Z","iopub.execute_input":"2024-06-22T14:37:53.464912Z","iopub.status.idle":"2024-06-22T14:37:53.470842Z","shell.execute_reply.started":"2024-06-22T14:37:53.464881Z","shell.execute_reply":"2024-06-22T14:37:53.470023Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import XLMRobertaTokenizerFast\n\n# Load the tokenizer\ntokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\", add_prefix_space=True)\n\ndef assign_labels(example):\n    claims = example['claims']\n    tokens = example['text_tokens']\n    labels = np.zeros(len(tokens))\n    for claim in claims:\n        start = claim['start']\n        end = claim['end']\n        for i in range(start, end):\n            labels[i] = 1\n    return labels\n\ndef align_labels_with_tokens(labels, word_ids):\n    new_labels = []\n    for word_id in word_ids:\n        if word_id is None:\n            new_labels.append(-100)\n        else:\n            new_labels.append(labels[word_id])\n    return new_labels\n\ndef preprocess(train_set, tokenizer):\n    new_labels = []\n    word_ids_list = []\n    encodings = tokenizer(train_set['text_tokens'].tolist(), is_split_into_words=True, padding=False)\n    for i, example in train_set.iterrows():\n        labels = assign_labels(example)\n        word_ids = encodings.word_ids(batch_index=i)\n        word_ids_list.append(word_ids)\n        new_labels.append(align_labels_with_tokens(labels, word_ids))\n    return encodings, new_labels ,word_ids_list\n\nclass CustomDataset(Dataset):\n    def __init__(self, dataset, tokenizer):\n        self.encodings, self.labels = preprocess(dataset, tokenizer)\n        self.input_ids = self.encodings['input_ids']\n        self.attention_mask = self.encodings['attention_mask']\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        input_ids = torch.tensor(self.input_ids[idx], dtype=torch.int64)\n        attention_mask = torch.tensor(self.attention_mask[idx], dtype=torch.int64)\n        labels = torch.tensor(self.labels[idx], dtype=torch.int64)\n        return input_ids, attention_mask, labels\n\ndef collate_fn(batch):\n    input_ids = [item[0] for item in batch]\n    attention_mask = [item[1] for item in batch]\n    labels = [item[2] for item in batch]\n\n    max_length = max(len(ids) for ids in input_ids)\n\n    padded_input_ids = torch.stack([torch.nn.functional.pad(ids, (0, max_length - len(ids)), value=tokenizer.pad_token_id) for ids in input_ids])\n    padded_attention_mask = torch.stack([torch.nn.functional.pad(mask, (0, max_length - len(mask)), value=0) for mask in attention_mask])\n    padded_labels = torch.stack([torch.nn.functional.pad(label, (0, max_length - len(label)), value=-100) for label in labels])\n\n    return padded_input_ids, padded_attention_mask, padded_labels\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-22T14:37:54.040108Z","iopub.execute_input":"2024-06-22T14:37:54.041049Z","iopub.status.idle":"2024-06-22T14:37:55.603454Z","shell.execute_reply.started":"2024-06-22T14:37:54.041009Z","shell.execute_reply":"2024-06-22T14:37:55.602668Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"input_ids = preprocess(val_en,tokenizer)[0]['input_ids']\ntargets =  preprocess(val_en,tokenizer)[1]\nword_ids =  preprocess(val_en,tokenizer)[2]","metadata":{"id":"F3crDLkUyTg9","execution":{"iopub.status.busy":"2024-06-22T14:37:55.605098Z","iopub.execute_input":"2024-06-22T14:37:55.605759Z","iopub.status.idle":"2024-06-22T14:37:55.904105Z","shell.execute_reply.started":"2024-06-22T14:37:55.605725Z","shell.execute_reply":"2024-06-22T14:37:55.903345Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"len(word_ids[0]) , len(targets[0]) , len(word_ids[0]), len(prediction[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-22T14:37:57.687754Z","iopub.execute_input":"2024-06-22T14:37:57.688444Z","iopub.status.idle":"2024-06-22T14:37:57.694501Z","shell.execute_reply.started":"2024-06-22T14:37:57.688415Z","shell.execute_reply":"2024-06-22T14:37:57.693670Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(51, 51, 51, 43)"},"metadata":{}}]},{"cell_type":"code","source":"def create_final_probability_list(predictions, word_ids):\n    final_probabilities = []\n\n    for row_idx in range(len(predictions)):\n        sum_dict = {}\n        count_dict = {}\n\n        for token_idx in range(len(predictions[row_idx])):\n            word_id = word_ids[row_idx][token_idx]\n            if word_id is not None:\n                if word_id not in sum_dict:\n                    sum_dict[word_id] = 0.0\n                    count_dict[word_id] = 0\n                sum_dict[word_id] += predictions[row_idx][token_idx]\n                count_dict[word_id] += 1\n\n        avg_predictions = {}\n        for word_id in sum_dict:\n            avg_predictions[word_id] = sum_dict[word_id] / count_dict[word_id]\n\n        final_probabilities.append(avg_predictions)\n\n    return final_probabilities","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mhesM2ET26P2","outputId":"666dd500-3061-4841-dbf8-46c403fd59f4","execution":{"iopub.status.busy":"2024-06-22T14:38:01.033011Z","iopub.execute_input":"2024-06-22T14:38:01.033361Z","iopub.status.idle":"2024-06-22T14:38:01.040513Z","shell.execute_reply.started":"2024-06-22T14:38:01.033335Z","shell.execute_reply":"2024-06-22T14:38:01.039668Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"probablity_list = np.array(create_final_probability_list(predictions, word_ids))\n\n#for missing wordIDs problem with XLMR tokeniser\n\ndef adjust_probabilities(text_tokens_list, probability_list):\n    adjusted_probabilities = []\n\n    for i in range(len(text_tokens_list)):\n        num_tokens = len(text_tokens_list[i])\n        probabilities = probability_list[i]\n\n        adjusted_prob = {word_id: 0.0 for word_id in range(num_tokens)}\n\n        for word_id, prob in probabilities.items():\n            adjusted_prob[word_id] = prob\n\n        adjusted_probabilities.append(adjusted_prob)\n\n    return adjusted_probabilities\n\nadjusted_probabilities = adjust_probabilities(val_en['text_tokens'], probablity_list)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T14:38:02.189098Z","iopub.execute_input":"2024-06-22T14:38:02.189746Z","iopub.status.idle":"2024-06-22T14:38:02.231203Z","shell.execute_reply.started":"2024-06-22T14:38:02.189717Z","shell.execute_reply":"2024-06-22T14:38:02.230364Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"threshold = 0.5\nfinal_submission = []\n\nfor dictionary in adjusted_probabilities:\n    y = [1 if value > threshold else 0 for value in dictionary.values()]\n    final_submission.append(y)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T14:38:04.492260Z","iopub.execute_input":"2024-06-22T14:38:04.493061Z","iopub.status.idle":"2024-06-22T14:38:04.500134Z","shell.execute_reply.started":"2024-06-22T14:38:04.493032Z","shell.execute_reply":"2024-06-22T14:38:04.499095Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"word_ids[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-21T15:54:32.591806Z","iopub.execute_input":"2024-06-21T15:54:32.592594Z","iopub.status.idle":"2024-06-21T15:54:32.599232Z","shell.execute_reply.started":"2024-06-21T15:54:32.592561Z","shell.execute_reply":"2024-06-21T15:54:32.598346Z"},"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"[None,\n 0,\n 1,\n 2,\n 2,\n 3,\n 4,\n 4,\n 5,\n 6,\n 6,\n 7,\n 8,\n 9,\n 9,\n 10,\n 11,\n 11,\n 12,\n 13,\n 14,\n 15,\n 15,\n 16,\n 17,\n 17,\n 18,\n 19,\n 20,\n 20,\n 21,\n 22,\n 23,\n 24,\n 24,\n 25,\n 25,\n 25,\n 26,\n 26,\n 26,\n 26,\n 26,\n 26,\n 26,\n 26,\n 26,\n 26,\n 26,\n 26,\n None]"},"metadata":{}}]},{"cell_type":"code","source":"probablity_list[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-21T15:53:40.913137Z","iopub.execute_input":"2024-06-21T15:53:40.913511Z","iopub.status.idle":"2024-06-21T15:53:40.920556Z","shell.execute_reply.started":"2024-06-21T15:53:40.913482Z","shell.execute_reply":"2024-06-21T15:53:40.919607Z"},"trusted":true},"execution_count":110,"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"{0: 0.002788395853713155,\n 1: 0.004873983561992645,\n 2: 0.003113170270808041,\n 3: 0.30393317341804504,\n 4: 0.8318581581115723,\n 5: 0.8045937418937683,\n 6: 0.12299303989857435,\n 7: 0.13307200372219086,\n 8: 0.11679500341415405,\n 9: 0.011267980560660362,\n 10: 0.014554060995578766,\n 11: 0.02543263416737318,\n 12: 0.008038471452891827,\n 13: 0.009613219648599625,\n 14: 0.045567646622657776,\n 15: 0.05991574563086033,\n 16: 0.06538075953722,\n 17: 0.05968308262526989,\n 18: 0.0770503580570221,\n 19: 0.1137475073337555,\n 20: 0.10871043428778648,\n 21: 0.16789878904819489,\n 22: 0.14478625357151031,\n 23: 0.14571265876293182,\n 24: 0.0025689737376524135,\n 25: 0.0006162291877747824,\n 26: 0.0004327175447542686}"},"metadata":{}}]},{"cell_type":"code","source":"import json\n\noutput_file = '11_xlmr-25Multisample.json'\n\nwith open(output_file, 'w') as f:\n    json.dump(final_submission, f)\n\nprint(f\"JSON file '{output_file}' has been created.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USGEqDeS_pKZ","outputId":"a9562713-5b7f-4f1f-c82f-011110edfc91","execution":{"iopub.status.busy":"2024-06-22T14:38:33.951566Z","iopub.execute_input":"2024-06-22T14:38:33.951923Z","iopub.status.idle":"2024-06-22T14:38:33.977372Z","shell.execute_reply.started":"2024-06-22T14:38:33.951897Z","shell.execute_reply":"2024-06-22T14:38:33.976474Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"JSON file '11_xlmr-25Multisample.json' has been created.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"WGDrcinvBr67"},"execution_count":null,"outputs":[]}]}